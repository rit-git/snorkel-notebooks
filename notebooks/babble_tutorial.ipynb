{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Babble Tutorial\n",
    "\n",
    "### You will work with Wikipedia plot descriptions of films that are either comedy or drama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nofarcarmeli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data.preparer import load_news_dataset\n",
    "from babble import Explanation\n",
    "from babble import BabbleStream\n",
    "from babble.Candidate import Candidate \n",
    "\n",
    "from metal.analysis import lf_summary\n",
    "from metal.analysis import label_coverage\n",
    "from metal import LabelModel\n",
    "from metal.tuners import RandomSearchTuner\n",
    "from babble.utils import ExplanationIO\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "stat_history = pd.DataFrame()\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "stat_history = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "These texts discuss either gun politics (1) or computer electronics (0).\n",
    "\n",
    "If you're not sure about the correct label, that's fine -- either make your best guess or just skip the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Unzip the data. (Don't worry about this, it should be already unzipped.)\n",
    "# Replace PASSWORD with the password to unzip the data, or download it directly from Kaggle.\n",
    "\n",
    "#!unzip -P PASSWORD data/data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into training, validation, development, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 training examples\n",
      "500 development examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nofarcarmeli/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_dev, df_valid, df_test = load_news_dataset()\n",
    "print(\"{} training examples\".format(len(df_train)))\n",
    "print(\"{} development examples\".format(len(df_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the labels for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "ELECTRONICS = 0\n",
    "GUNS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_lfs</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-31 18:40:13.458286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_lfs                       time\n",
       "0      0.0 2020-01-31 18:40:13.458286"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start timer\n",
    "stat_history.append({\"time\": datetime.now(), \"num_lfs\": 0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data into a format compatible with Babble Labble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper class to transform our data into a format Babble can parse\n",
    "\n",
    "dfs = [df_train, df_dev, df_test]\n",
    "\n",
    "for df in dfs:\n",
    "    df[\"id\"] = range(len(df))\n",
    "\n",
    "Cs = [df.apply(lambda x: Candidate(x), axis=1) for df in dfs]\n",
    "\n",
    "# babble labble uses 1 and 2 for labels, while our data uses 0 and 1\n",
    "# add 1 to convert\n",
    "Ys = [df.label.values + 1 for df in dfs]\n",
    "Ys[0] -= 1 # no label (training set) should be set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a *BabbleStream*: an object that iteratively displays candidates, collects and parses explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar construction complete.\n"
     ]
    }
   ],
   "source": [
    "# aliases are a way to refer to a set of words in a rule.\n",
    "aliases = {\"units\": [\"joules\", \"volts\", \"ohms\", \"MHz\"]}\n",
    "babbler = BabbleStream(Cs, Ys, balanced=True, shuffled=True, seed=456, aliases=aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyprint(candidate):\n",
    "    # just a helper function to print the candidate nicely\n",
    "    print(candidate.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example candidate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just installed a Motorola XC68882RC50 FPU in an Amiga A2630 board (25 MHz\n",
      "68030 + 68882 with capability to clock the FPU separately).  Previously\n",
      "a MC68882RC25 was installed and everything was working perfectly.  Now the\n",
      "systems displays a yellow screen (indicating a exception) when it check for\n",
      "the presence/type of FPU.  When I reinstall an MC68882RC25 the system works\n",
      "fine, but with the XC68882 even at 25 MHz it does not work.  The designer\n",
      "of the board mentioned that putting a pullup resistor on data_strobe (470 Ohm)\n",
      "might help, but that didn't change anything.  Does anybody have some\n",
      "suggestions what I could do?  Does this look like a CPU-FPU communications\n",
      "problem or is the particular chip dead (it is a pull, not new)?\n",
      "Moreover, the place I bought it from is sending me an XC68882RC33.  I thought\n",
      "that the 68882RC33 were labeled MC not XC (for not finalized mask design). \n",
      "Are there any MC68882RC33?\n"
     ]
    }
   ],
   "source": [
    "candidate = babbler.next()\n",
    "prettyprint(candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll learn how to write a labelling function from a natural language explanation of why you chose a label for a given candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Explanations\n",
    "\n",
    "Creating explanations generally happens in five steps:\n",
    "1. View candidates\n",
    "2. Write explanations\n",
    "3. Get feedback\n",
    "4. Update explanations \n",
    "5. Apply label aggregator\n",
    "\n",
    "Steps 3-5 are optional; explanations may be submitted without any feedback on their quality. However, in our experience, observing how well explanations are being parsed and what their accuracy/coverage on a dev set are (if available) can quickly lead to simple improvements that yield significantly more useful labeling functions. Once a few labeling functions have been collected, you can use the label aggregator to identify candidates that are being mislabeled and write additional explanations targeting those failure modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your task for this tutorial is to write 5 labeling functions.__\n",
    "\n",
    "Feel free to consult the internet or ask your experiment leader.\n",
    "\n",
    "*(For the real task, you will be asked to write 10 labeling functions, as quickly and accurately as possible. You will still be allowed to use the internet in this phase, but not ask your experiment leader.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection\n",
    "\n",
    "Use `babbler` to show candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Those rules/regulations/laws would be subject to the same attack:  that\n",
      "they are attempting to preempt federal authority to regulate (or not)\n",
      "radio communications.  Of course, as the original poster noted, court\n",
      "challenges of this kind can get expensive.\n"
     ]
    }
   ],
   "source": [
    "candidate = babbler.next()\n",
    "prettyprint(candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it about guns or electronics? What makes you think that? (If you don't know, it's okay to make your best guess or skip an example.)\n",
    "\n",
    "Run the three examples given below, then parse them, and analyze them.\n",
    "Then, you can try editing them and writing your own functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = Explanation(\n",
    "    # name of this rule, for your reference\n",
    "    name='power units', \n",
    "    # label to assign\n",
    "    label=ELECTRONICS, \n",
    "    # natural language description of why you label the candidate this way\n",
    "    condition='because units occur', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = Explanation(\n",
    "    name = 'firearm', \n",
    "    label = GUNS, \n",
    "    condition = 'because \"doesn\\'t\" occurs between \"system\" and \"work\"', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of an explanation that uses an alias: \"couples\"\n",
    "\n",
    "You can define more aliases where the BabbleStream is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = Explanation(\n",
    "    name = 'defense', \n",
    "    label = GUNS, \n",
    "    condition = 'because \"defense\" occurs between \"self\" and \"gun\"', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = Explanation(\n",
    "    name = \"e3\", \n",
    "    label = ABSTAIN, \n",
    "    condition = \"\", \n",
    "    # candidate is an optional argument, it should be the id of an example labeled by this rule.\n",
    "    # if the rule doesn't apply to the candidate you provide, it will be filtered!\n",
    "    #candidate = candidate.mention_id \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4 = Explanation(\n",
    "    name = \"e4\", \n",
    "    label = ABSTAIN, \n",
    "    condition = \"\", \n",
    "    #candidate = candidate.mention_id \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = [e0, e1, e2, e3, e4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Babble will parse your explanations into functions, then filter out functions that are duplicates, incorrectly label their given candidate, or assign the same label to all examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 0 unique target candidate ids from 5 explanations.\n",
      "No candidate hashes were provided. Skipping linking.\n",
      "2 explanation(s) out of 5 were parseable.\n",
      "4 parse(s) generated from 5 explanation(s).\n",
      "2 parse(s) remain (2 parse(s) removed by DuplicateSemanticsFilter).\n",
      "Note: 2 LFs did not have candidates and therefore could not be filtered.\n",
      "2 parse(s) remain (0 parse(s) removed by ConsistencyFilter).\n",
      "Applying labeling functions to investigate labeling signature.\n",
      "[========================================] 100%\n",
      "\n",
      "0 parse(s) remain (2 parse(s) removed by UniformSignatureFilter: (2 None, 0 All)).\n"
     ]
    }
   ],
   "source": [
    "parses, filtered = babbler.apply(explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "See how your parsed explanations performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-28e995c15029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbabbler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/babble/babbler.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, parses)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlf_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlf_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfiltered_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_parses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/metal/analysis.py\u001b[0m in \u001b[0;36mlf_summary\u001b[0;34m(L, Y, lf_names, est_accs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Coverage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_coverages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Overlaps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_overlaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Conflicts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_conflicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlf_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/metal/analysis.py\u001b[0m in \u001b[0;36mlf_conflicts\u001b[0;34m(L, normalize_by_overlaps)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0mof\u001b[0m \u001b[0mLF\u001b[0m \u001b[0moverlaps\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mconflicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mconflicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0m_conflicted_data_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize_by_overlaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mconflicts\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlf_overlaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/metal/analysis.py\u001b[0m in \u001b[0;36m_conflicted_data_points\u001b[0;34m(L)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"Returns an indicator vector where ith element = 1 if x_i is labeled by\n\u001b[1;32m     34\u001b[0m     at least two LFs that give it disagreeing labels.\"\"\"\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(self, axis, out)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \"\"\"\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_or_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_min_or_max\u001b[0;34m(self, axis, out, min_or_max)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_or_max_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_or_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/snorkel-notebooks/venv/lib/python3.7/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_min_or_max_axis\u001b[0;34m(self, axis, min_or_max)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zero-size array to reduction operation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation"
     ]
    }
   ],
   "source": [
    "babbler.analyze(parses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See which explanations were filtered and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "7 TOTAL:\n",
      "3 Unparseable Explanation\n",
      "2 Duplicate Semantics\n",
      "0 Inconsistency with Example\n",
      "2 Uniform Signature\n",
      "0 Duplicate Signature\n",
      "0 Lowest Coverage\n",
      "\n",
      "[#1]: Unparseable Explanation\n",
      "\n",
      "Explanation: because units occur in the text\n",
      "\n",
      "Reason: This explanation couldn't be parsed.\n",
      "\n",
      "Semantics: None\n",
      "\n",
      "\n",
      "[#2]: Unparseable Explanation\n",
      "\n",
      "Explanation: \n",
      "\n",
      "Reason: This explanation couldn't be parsed.\n",
      "\n",
      "Semantics: None\n",
      "\n",
      "\n",
      "[#3]: Unparseable Explanation\n",
      "\n",
      "Explanation: \n",
      "\n",
      "Reason: This explanation couldn't be parsed.\n",
      "\n",
      "Semantics: None\n",
      "\n",
      "\n",
      "[#4]: Duplicate Semantics\n",
      "\n",
      "Parse: return 1 if 'not'.(.eq(z) for all z in ['do','work']) else 0\n",
      "\n",
      "Reason: This parse is identical to one produced by the following explanation:\n",
      "\t\"because \"not\" occurs between \"do\" and \"work\"\"\n",
      "\n",
      "Semantics: ('.root', ('.label', ('.int', 1), ('.call', ('.composite_and', ('.eq',), ('.list', ('.string', 'do'), ('.string', 'work'))), ('.string', 'not'))))\n",
      "\n",
      "\n",
      "[#5]: Duplicate Semantics\n",
      "\n",
      "Parse: return 1 if 'defense'.(.eq(z) for all z in ['self','gun']) else 0\n",
      "\n",
      "Reason: This parse is identical to one produced by the following explanation:\n",
      "\t\"because \"defense\" occurs between \"self\" and \"gun\"\"\n",
      "\n",
      "Semantics: ('.root', ('.label', ('.int', 1), ('.call', ('.composite_and', ('.eq',), ('.list', ('.string', 'self'), ('.string', 'gun'))), ('.string', 'defense'))))\n",
      "\n",
      "\n",
      "[#6]: Uniform Signature\n",
      "\n",
      "Parse: return 1 if 'not'.(.eq(z) for all z in ['do','work']) else 0\n",
      "\n",
      "Reason: This parse labeled NONE of the 500 development examples\n",
      "\n",
      "Semantics: ('.root', ('.label', ('.int', 1), ('.call', ('.composite_and', ('.eq',), ('.list', ('.string', 'do'), ('.string', 'work'))), ('.string', 'not'))))\n",
      "\n",
      "\n",
      "[#7]: Uniform Signature\n",
      "\n",
      "Parse: return 1 if 'defense'.(.eq(z) for all z in ['self','gun']) else 0\n",
      "\n",
      "Reason: This parse labeled NONE of the 500 development examples\n",
      "\n",
      "Semantics: ('.root', ('.label', ('.int', 1), ('.call', ('.composite_and', ('.eq',), ('.list', ('.string', 'self'), ('.string', 'gun'))), ('.string', 'defense'))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "babbler.filtered_analysis(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "babbler.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Get feedback on the performance of your explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls = [babbler.get_label_matrix(split) for split in [0,1,2]]\n",
    "lf_names = [lf.__name__ for lf in babbler.get_lfs()]\n",
    "lf_summary(Ls[1], Ys[1], lf_names=lf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'n_epochs': [50, 100, 500],\n",
    "    'lr': {'range': [0.01, 0.001], 'scale': 'log'},\n",
    "    'show_plots': False,\n",
    "}\n",
    "\n",
    "tuner = RandomSearchTuner(LabelModel, seed=123)\n",
    "\n",
    "label_aggregator = tuner.search(\n",
    "    search_space, \n",
    "    train_args=[Ls[0]], \n",
    "    X_dev=Ls[1], Y_dev=Ys[1], \n",
    "    max_search=20, verbose=False, metric='f1')\n",
    "\n",
    "# record statistics over time\n",
    "pr, re, f1 = label_aggregator.score(Ls[1], Ys[1], metric=['precision', 'recall', 'f1'])\n",
    "stats = {\n",
    "    \"precision\": pr,\n",
    "    \"recall\": re,\n",
    "    \"f1\": f1,\n",
    "    \"time\": datetime.now(),\n",
    "    \"training_label_coverage\": label_coverage(Ls[0]),\n",
    "    \"training_label_size\": label_coverage(Ls[0])*len(dfs[0])\n",
    "}\n",
    "stat_history = stat_history.append(stats, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to save the explanations you've generated, you can use the `ExplanationIO` object to write to or read them from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_history.to_csv(\"babbler_tutorial_statistics_history.csv\")\n",
    "FILE = \"babbler_tutorial_explanations.tsv\"\n",
    "exp_io = ExplanationIO()\n",
    "exp_io.write(explanations, FILE)\n",
    "explanations = exp_io.read(FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "We can train a simple bag of words model on these labels, and see test accuracy.\n",
    "\n",
    "(This step may take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_aggregator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-a38170fc1f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_aggregator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_aggregator' is not defined"
     ]
    }
   ],
   "source": [
    "from analyzer import train_model\n",
    "\n",
    "train_model(label_aggregator, df_train, df_valid, df_test, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
